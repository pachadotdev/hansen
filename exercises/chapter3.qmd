
# Chapter 3. The Algebra of Least Squares

## Exercise 3.24

Use the `cps09mar dataset described in Section 3.22 and available on the textbook website. Take the subsample used for equation (3.49) for data construction,

a. Estimate equation (3.49), and compute the equation $R^2$ and sum of square errors.
b. Re-estimate the slope on education using the residual regression approach. Regress $\log(\text{wage})$ on experience and its square, regress education on experience and its square, and the residuals on the residuals. Report the estimates from this final regression, along with the equation $R^2$ and sum of squared errors. Does the slope coefficient equal the value in (3.49)? Explain.
c. Are the $R^2$ and sum of squared errors from parts (a) and (b) equal? Explain.

### Solution

#### Part (a)

Equation (3.49) is given by

$$
\hat{\log(\text{wage})} = 0.144 \text{education} + 0.043 \text{experience} - 0.095 \text{experience}^2 / 100 + 0.531.
$$

The estimates are obtained using the following code:

```{r}
library(hansen) # data
library(dplyr) # data manipulation
library(broom) # tidy output

glimpse(cps09mar)

levels(cps09mar$education)
levels(cps09mar$female)
levels(cps09mar$race)
levels(cps09mar$marital)

data_324a <- cps09mar %>%
  mutate(
    wage = earnings / (hours * week),
    education2 = case_when(
      education == "Less than 1st grade" ~ 0,
      education == "1st to 4th grade" ~ 4,
      education == "5th or 6th grade" ~ 6,
      education == "7th or 8th grade" ~ 8,
      education == "9th grade" ~ 9,
      education == "10th grade" ~ 10,
      education == "11th grade or 12th grade without diploma" ~ 11,
      education == "High school graduate or equivalent" ~ 12,
      education == "Some college, no degree" ~ 13,
      education == "Associate degree (occupational/vocational programs included)" ~ 14,
      education == "Bachelor's degree (BA, AB, BS)" ~ 16,
      education == "Master's degree (MA, MS, MEng, MEd, MSW, MBA)" ~ 18,
      education == "Professional or Doctorate degree (MD, DDS, DVM, JD, PhD, EdD)" ~ 20,
      TRUE ~ NA_real_
    ),
    experience = age - education2 - 6
  ) %>%
  filter(
    experience < 45 &
      female == "No" &
      race == "Asian only" &
      marital == "Never married"
  )

dim(data_324a)

fit_324a <- lm(log(wage) ~ education2 + experience + I(experience^2 / 100), data = data_324a)

tidy(fit_324a)

glance(fit_324a)

sum(resid(fit_324a)^2)
```

#### Part (b)

The residual regression approach can be implemented as follows:

```{r}
# Regress log(wage) on experience and its square
fit_324b1 <- lm(log(wage) ~ experience + I(experience^2 / 100), data = data_324a)
resid_324b1 <- resid(fit_324b1)

# Regress education2 on experience and its square
fit_324b2 <- lm(education2 ~ experience + I(experience^2 / 100), data = data_324a)
resid_324b2 <- resid(fit_324b2)

# Regress residuals on residuals
fit_324b3 <- lm(resid_324b1 ~ resid_324b2)

tidy(fit_324b3)

glance(fit_324b3)

sum(resid(fit_324b3)^2)

all.equal(unname(coef(fit_324a)[2]), unname(coef(fit_324b3)[2]))
```

The coefficients are equal because the residual regression approach is equivalent to the original regression.

#### Part (c)

A proper comparison accounts for the floating point operations involved in the $R^2$:

```{r}
all.equal(glance(fit_324a)$r.squared, glance(fit_324b3)$r.squared)
```

The $R^2$ values are not equal because the R computation uses a different number of degrees of freedom for each model.

An alternative to this is to look at $R^2$ equation from Section 3.14 and verify that the
sum of the squared residuals is the same for both models, but the centred variable
is different:

```{r}
sq_resid <- function(e) { sum(e^2) }
sq_yc <- function(y) { sum((y - mean(y))^2) }

all.equal(sq_resid(resid(fit_324a)), sq_resid(resid(fit_324b3)))
all.equal(sq_yc(log(data_324a$wage)), sq_yc(fitted(fit_324b3)))
```

## Exercise 3.26

a. Estimate a log wage regression for the subsample of white male Hispanics. In addition to education, experience, and its square, incldue a set of binary variables for regions and marital status. For regions, create dummy variables for Northeast, South, and West, so that Midwest is the excluded group. For marital status, create variables for married, widowed, or divorced, and separated, so that single (never married) is the excluded group.
b. Repeat using a different econometric package. Compare your results. Do you obtain the same results?
