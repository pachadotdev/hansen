---
title: "Chapter 3. The Algebra of Least Squares"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{"Chapter 3. The Algebra of Least Squares"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Load the data and create subsamples

We process the data with the following code:

```{r}
library(hansen)

experience <- cps09mar$age - cps09mar$education_num - 6
mbf <- (cps09mar$race_num == 2) & (cps09mar$marital_num <= 2) &
  (cps09mar$female_num == 1) & (experience == 12)
sam <- (cps09mar$race_num == 4) & (cps09mar$marital_num == 7) &
  (cps09mar$female_num == 0)
dat1 <- cps09mar[mbf, ]
dat2 <- cps09mar[sam, ]

dim(dat1)
dim(dat2)
```

# First regression

The C++ code for the OLS estimator is as follows:

```cpp
Mat<double> ols_(const Mat<double>& Y, const Mat<double>& X) {
  Mat<double> XtX = X.t() * X;             // X'X
  Mat<double> XtX_inv = inv(XtX);          // (X'X)^(-1)
  Mat<double> beta = XtX_inv * X.t() * Y;  // (X'X)^(-1)(X'Y)

  return beta;
}

[[cpp11::register]] doubles_matrix<> ols_r_(const doubles_matrix<>& y,
                                            const doubles_matrix<>& x) {
  Mat<double> Y = as_Mat(y);  // Col<double> Y = as_Col(y); also works
  Mat<double> X = as_Mat(x);
  Mat<double> beta = ols_(Y, X);
  return as_doubles_matrix(beta);
}
```

The function must be exposed and documented so that it can be used by the
end-user:

```r
#' OLS estimation
#' @param y dependent variable
#' @param x independent variables
#' @return matrix of OLS estimates
#' @export
ols <- function(y, x) {
  ols_r_(y, x)
}
```

Every time you need to test a new function or changes to a function, run
`devtools::load_all()` to load the new function or its changes into the
R environment.

To use the function, it is required to create a model matrix and a response
vector:

```{r}
y <- as.matrix(log(dat1$earnings / (dat1$hours * dat1$week)))
X <- cbind(1, dat1$education_num)
ols(y, X)
```

# Second regression

```{r}
y <- as.matrix(log(dat2$earnings / (dat2$hours * dat2$week)))
experience <- dat2$age - dat2$education_num - 6
experience2 <- (experience^2) / 100
x <- cbind(1, dat2$education_num, experience, experience2)
colnames(x) <- c("constant", "education", "experience", "experience2")
ols(y, x)
```

# Create leverage and influence

The influence function can be written in C++ to practice, and it is a good idea
to separate the residuals from the leverage to keep the code modular:

```cpp
double influence_(const doubles_matrix<>& y, const doubles_matrix<>& x) {
  Mat<double> Y = as_Mat(y);
  Mat<double> X = as_Mat(x);

  Mat<double> e = Y - (X * ols_(Y, X));
  Mat<double> XXi = inv(X.t() * X);
  Mat<double> leverage = sum(X % (X * XXi), 1);
  Mat<double> ones = Mat<double>(Y.n_rows, 1, fill::ones);
  Mat<double> d = (leverage % e) / (ones - leverage);

  return as_scalar(max(abs(d)));
}

[[cpp11::register]] double influence_r_(const doubles_matrix<>& y,
                                        const doubles_matrix<>& x) {
  return influence_(y, x);
}
```

This function also needs to be exposed and documented:

```r
#' Influence function
#' @inheritParams ols
#' @return numerical value of influence function
#' @export
influence <- function(y, x) {
  influence_r_(y, x)
}
```

From now, it will be assumed that the functions need to be exposed and
documented for the end-user to use them.

```{r}
max(abs(influence(y, x)))
```

# Regression with restricted sample

This is identical to the OLS estimator, but changing the input data:

```{r}
x_r <- x[x[, "education"] < 45, ]
y_r <- y[x[, "education"] < 45, ]
ols(y_r, x_r)
```
